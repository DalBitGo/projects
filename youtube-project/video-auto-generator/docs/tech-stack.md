# ê¸°ìˆ  ìŠ¤íƒ ìƒì„¸ ë¬¸ì„œ

## ê°œìš”

ì „ì²´ ìŠ¤íƒì€ **Python ê¸°ë°˜ ë°±ì—”ë“œ + FFmpeg ë¯¸ë””ì–´ ì²˜ë¦¬ + ì„ íƒì  ì›¹ UI**ë¡œ êµ¬ì„±

---

## ì½”ì–´ ê¸°ìˆ 

### Python 3.10+

**ì„ íƒ ì´ìœ **:
- ë¯¸ë””ì–´ ì²˜ë¦¬ ë¼ì´ë¸ŒëŸ¬ë¦¬ í’ë¶€ (MoviePy, Pillow, pydub)
- FFmpeg ë˜í¼ ì§€ì› ìš°ìˆ˜
- ë°ì´í„° ì²˜ë¦¬ (Pandas) ë° API í†µí•© ìš©ì´
- ë¹„ë™ê¸° ì‘ì—… (Celery) ìƒíƒœê³„ ì„±ìˆ™

**ì£¼ìš” íŒ¨í‚¤ì§€**:
```python
# requirements.txt
pillow==10.2.0          # ì´ë¯¸ì§€ ì²˜ë¦¬
moviepy==1.0.3          # ì˜ìƒ í¸ì§‘
pandas==2.1.4           # ë°ì´í„° ì²˜ë¦¬
pydub==0.25.1           # ì˜¤ë””ì˜¤ ì²˜ë¦¬
opencv-python==4.9.0    # ê³ ê¸‰ ì˜ìƒ ì²˜ë¦¬
numpy==1.26.3           # ìˆ˜ì¹˜ ì—°ì‚°

# API & Web
fastapi==0.109.0        # REST API
uvicorn==0.27.0         # ASGI ì„œë²„
celery==5.3.4           # ë¹„ë™ê¸° ì‘ì—…
redis==5.0.1            # ìºì‹œ & í
pydantic==2.5.3         # ë°ì´í„° ê²€ì¦

# External APIs
requests==2.31.0        # HTTP í´ë¼ì´ì–¸íŠ¸
google-api-python-client==2.115.0  # YouTube API
openai==1.10.0          # LLM (optional)

# Utils
python-dotenv==1.0.0    # í™˜ê²½ë³€ìˆ˜
pyyaml==6.0.1           # ì„¤ì • íŒŒì¼
tqdm==4.66.1            # ì§„í–‰ë¥  í‘œì‹œ
click==8.1.7            # CLI ë„êµ¬
```

---

### FFmpeg

**ë²„ì „**: 6.0+

**ì„ íƒ ì´ìœ **:
- ì—…ê³„ í‘œì¤€ ë¯¸ë””ì–´ ì²˜ë¦¬ ë„êµ¬
- ë³µì¡í•œ í•„í„° ì²´ì¸ ì§€ì›
- í•˜ë“œì›¨ì–´ ê°€ì† (NVENC, QSV, VideoToolbox)
- ë¬´ë£Œ & ì˜¤í”ˆì†ŒìŠ¤

**ì„¤ì¹˜**:
```bash
# Ubuntu/Debian
sudo apt update && sudo apt install ffmpeg

# macOS
brew install ffmpeg

# Windows
choco install ffmpeg

# ë²„ì „ í™•ì¸
ffmpeg -version
```

**ì£¼ìš” ê¸°ëŠ¥ í™œìš©**:
```bash
# ë¦¬ì‚¬ì´ì¦ˆ & í¬ë¡­
-vf "scale=1080:1920:force_original_aspect_ratio=increase,crop=1080:1920"

# ë¸”ëŸ¬ ì²˜ë¦¬
-vf "gblur=sigma=50"

# ì˜¤ë²„ë ˆì´
-filter_complex "[0:v][1:v]overlay=x:y"

# í…ìŠ¤íŠ¸ ë²ˆì¸
-vf "drawtext=fontfile=font.ttf:text='Hello':x=10:y=10:fontsize=24"

# ì „í™˜ íš¨ê³¼ (xfade)
-filter_complex "xfade=transition=fade:duration=1:offset=5"

# í•˜ë“œì›¨ì–´ ê°€ì† (NVIDIA)
-hwaccel cuda -c:v h264_cuvid ... -c:v h264_nvenc

# ì˜¤ë””ì˜¤ ë¯¹ì‹±
-filter_complex "[0:a][1:a]amix=inputs=2:duration=longest"
```

---

## ë¯¸ë””ì–´ ì²˜ë¦¬ ë¼ì´ë¸ŒëŸ¬ë¦¬

### Pillow (PIL Fork)

**ìš©ë„**: í…œí”Œë¦¿ ì´ë¯¸ì§€ ìƒì„±, ì˜¤ë²„ë ˆì´, ì¸ë„¤ì¼

**ì£¼ìš” ê¸°ëŠ¥**:
```python
from PIL import Image, ImageDraw, ImageFont, ImageFilter

# ì´ë¯¸ì§€ ìƒì„±
img = Image.new('RGBA', (1080, 1920), (255, 255, 255, 0))

# í…ìŠ¤íŠ¸ ë Œë”ë§
draw = ImageDraw.Draw(img)
font = ImageFont.truetype("font.ttf", 72)
draw.text((540, 960), "ì œëª©", font=font, fill=(255, 255, 255), anchor="mm")

# ë‘¥ê·¼ ëª¨ì„œë¦¬
def add_rounded_corners(img, radius):
    mask = Image.new('L', img.size, 0)
    draw = ImageDraw.Draw(mask)
    draw.rounded_rectangle([(0, 0), img.size], radius, fill=255)
    img.putalpha(mask)
    return img

# ê·¸ë¼ë°ì´ì…˜ ìƒì„±
def create_gradient(start_color, end_color, width, height):
    base = Image.new('RGB', (width, height), start_color)
    top = Image.new('RGB', (width, height), end_color)
    mask = Image.new('L', (width, height))
    for y in range(height):
        mask.putpixel((0, y), int(255 * (y / height)))
    base.paste(top, (0, 0), mask)
    return base

# ë¸”ëŸ¬
img = img.filter(ImageFilter.GaussianBlur(radius=20))

# ì €ì¥
img.save('output.png', 'PNG')
```

**í•œê¸€ í°íŠ¸**:
```python
# Noto Sans CJK ë‹¤ìš´ë¡œë“œ
# https://fonts.google.com/noto/specimen/Noto+Sans+KR

font_bold = ImageFont.truetype("NotoSansKR-Bold.ttf", 70)
font_regular = ImageFont.truetype("NotoSansKR-Regular.ttf", 50)
```

**ì´ëª¨ì§€ ì§€ì›**:
```python
# Noto Color Emoji í•„ìš”
# https://fonts.google.com/noto/specimen/Noto+Color+Emoji

emoji_font = ImageFont.truetype("NotoColorEmoji.ttf", 100)
draw.text((100, 100), "ğŸ˜¹", font=emoji_font, embedded_color=True)
```

---

### MoviePy

**ìš©ë„**: ê³ ìˆ˜ì¤€ ì˜ìƒ í¸ì§‘ (Python API)

**ì¥ì **:
- Python ë„¤ì´í‹°ë¸Œ API (FFmpeg ë˜í¼)
- ì§ê´€ì ì¸ í´ë¦½ ì¡°ì‘
- ì „í™˜ íš¨ê³¼ ë‚´ì¥

**ë‹¨ì **:
- FFmpeg ì§ì ‘ ì‚¬ìš©ë³´ë‹¤ ëŠë¦¼
- ë©”ëª¨ë¦¬ ì‚¬ìš© ë§ìŒ

**ì£¼ìš” ê¸°ëŠ¥**:
```python
from moviepy.editor import *

# í´ë¦½ ë¡œë“œ
clip = VideoFileClip("input.mp4")

# ìë¥´ê¸°
clip = clip.subclip(5, 15)  # 5ì´ˆ~15ì´ˆ

# ë¦¬ì‚¬ì´ì¦ˆ
clip = clip.resize(height=1920)

# í¬ë¡­
clip = clip.crop(x1=100, y1=200, x2=1180, y2=2120)

# ì†ë„ ì¡°ì ˆ
clip = clip.speedx(1.5)  # 1.5ë°°ì†

# í…ìŠ¤íŠ¸
txt = TextClip("ì œëª©", fontsize=70, color='white', font='NotoSansKR-Bold')
txt = txt.set_position(('center', 'bottom')).set_duration(clip.duration)

# í•©ì„±
video = CompositeVideoClip([clip, txt])

# ì—°ê²°
final = concatenate_videoclips([clip1, clip2, clip3], method="compose")

# ì „í™˜ íš¨ê³¼
final = concatenate_videoclips([clip1, clip2], method="compose", padding=-1)  # crossfade

# ì˜¤ë””ì˜¤
audio = AudioFileClip("bgm.mp3")
video = video.set_audio(audio)

# ë Œë”ë§
video.write_videofile(
    "output.mp4",
    fps=30,
    codec='libx264',
    audio_codec='aac',
    preset='medium',  # ultrafast, fast, medium, slow
    threads=4
)
```

**ì‚¬ìš© ì „ëµ**:
- ê°„ë‹¨í•œ ì‘ì—…: MoviePy (ë¹ ë¥¸ í”„ë¡œí† íƒ€ì´í•‘)
- ë³µì¡í•œ ì‘ì—…: FFmpeg ì§ì ‘ ì‚¬ìš© (ì„±ëŠ¥)

---

### pydub

**ìš©ë„**: ì˜¤ë””ì˜¤ í¸ì§‘

**ì£¼ìš” ê¸°ëŠ¥**:
```python
from pydub import AudioSegment
from pydub.effects import normalize

# ë¡œë“œ
audio = AudioSegment.from_file("audio.mp3")

# ìë¥´ê¸°
clip = audio[5000:15000]  # 5ì´ˆ~15ì´ˆ (ms ë‹¨ìœ„)

# ë³¼ë¥¨ ì¡°ì ˆ
quiet = audio - 10  # -10dB
loud = audio + 5    # +5dB

# í˜ì´ë“œ
audio = audio.fade_in(2000).fade_out(2000)

# ë¯¹ì‹±
mixed = audio1.overlay(audio2)

# Normalize
audio = normalize(audio)

# Export
audio.export("output.mp3", format="mp3", bitrate="192k")
```

**Ducking (ìŒì„± ë‚˜ì˜¬ ë•Œ BGM ì¤„ì´ê¸°)**:
```python
def duck_bgm(voice: AudioSegment, bgm: AudioSegment, duck_amount: int = 15):
    """
    voice: ìŒì„± íŠ¸ë™
    bgm: ë°°ê²½ìŒì•…
    duck_amount: BGM ê°ì†ŒëŸ‰ (dB)
    """
    # BGM ê¸¸ì´ ë§ì¶”ê¸°
    if len(bgm) < len(voice):
        bgm = bgm * ((len(voice) // len(bgm)) + 1)
    bgm = bgm[:len(voice)]

    # Ducking (ê°„ë‹¨ ë²„ì „ - ì „ì²´ êµ¬ê°„)
    ducked_bgm = bgm - duck_amount

    # ë¯¹ì‹±
    return voice.overlay(ducked_bgm)

# ì‚¬ìš©
result = duck_bgm(voice_audio, bgm_audio)
result.export("mixed.mp3", format="mp3")
```

---

## ì™¸ë¶€ API

### Pexels API

**ìš©ë„**: ë¬´ë£Œ ìŠ¤í†¡ ì˜ìƒ/ì´ë¯¸ì§€

**ê°€ê²©**: ë¬´ë£Œ (Rate limit: 200 req/hour)

**ë¬¸ì„œ**: https://www.pexels.com/api/documentation/

**API í‚¤ ë°œê¸‰**:
1. https://www.pexels.com/api/ ì ‘ì†
2. ê³„ì • ìƒì„± & API í‚¤ ë°œê¸‰

**ì‚¬ìš© ì˜ˆì‹œ**:
```python
import requests

PEXELS_API_KEY = "YOUR_API_KEY"

def search_pexels_videos(query: str, orientation: str = "portrait", per_page: int = 10):
    url = "https://api.pexels.com/videos/search"
    headers = {"Authorization": PEXELS_API_KEY}
    params = {
        "query": query,
        "orientation": orientation,  # portrait, landscape, square
        "per_page": per_page
    }

    response = requests.get(url, headers=headers, params=params)
    data = response.json()

    videos = []
    for video in data.get('videos', []):
        # ìµœê³  í™”ì§ˆ ì„ íƒ
        video_files = sorted(video['video_files'], key=lambda x: x.get('width', 0), reverse=True)
        videos.append({
            'id': video['id'],
            'url': video_files[0]['link'],
            'duration': video['duration'],
            'width': video_files[0]['width'],
            'height': video_files[0]['height'],
            'thumbnail': video['image']
        })

    return videos

# ê²€ìƒ‰
results = search_pexels_videos("cat funny", orientation="portrait")
print(f"Found {len(results)} videos")

# ë‹¤ìš´ë¡œë“œ
def download_video(url: str, output_path: str):
    response = requests.get(url, stream=True)
    with open(output_path, 'wb') as f:
        for chunk in response.iter_content(chunk_size=8192):
            f.write(chunk)

download_video(results[0]['url'], "video.mp4")
```

---

### Pixabay API

**ìš©ë„**: ëŒ€ì•ˆ ìŠ¤í†¡ ì†ŒìŠ¤

**ê°€ê²©**: ë¬´ë£Œ (Rate limit: 100 req/min)

**ë¬¸ì„œ**: https://pixabay.com/api/docs/

**ì‚¬ìš© ì˜ˆì‹œ**:
```python
PIXABAY_API_KEY = "YOUR_API_KEY"

def search_pixabay_videos(query: str, per_page: int = 10):
    url = "https://pixabay.com/api/videos/"
    params = {
        "key": PIXABAY_API_KEY,
        "q": query,
        "per_page": per_page
    }

    response = requests.get(url, params=params)
    data = response.json()

    videos = []
    for hit in data.get('hits', []):
        # 'large' í™”ì§ˆ ì„ íƒ
        video_url = hit['videos']['large']['url']
        videos.append({
            'id': hit['id'],
            'url': video_url,
            'duration': hit['duration'],
            'width': hit['videos']['large']['width'],
            'height': hit['videos']['large']['height']
        })

    return videos
```

---

### Google Cloud TTS (ì„ íƒ)

**ìš©ë„**: ê³ í’ˆì§ˆ í•œêµ­ì–´ TTS (Vrew ëŒ€ì•ˆ)

**ê°€ê²©**: $16 / 1M ë¬¸ì (ë¬´ë£Œ í• ë‹¹: 0-4M ë¬¸ì/ì›”)

**ë¬¸ì„œ**: https://cloud.google.com/text-to-speech/docs

**ì„¤ì •**:
```bash
# 1. GCP í”„ë¡œì íŠ¸ ìƒì„±
# 2. Cloud TTS API í™œì„±í™”
# 3. ì„œë¹„ìŠ¤ ê³„ì • í‚¤ ë‹¤ìš´ë¡œë“œ (JSON)

export GOOGLE_APPLICATION_CREDENTIALS="path/to/credentials.json"

# SDK ì„¤ì¹˜
pip install google-cloud-texttospeech
```

**ì‚¬ìš© ì˜ˆì‹œ**:
```python
from google.cloud import texttospeech

def generate_tts(text: str, output_path: str, voice_name: str = "ko-KR-Neural2-A"):
    client = texttospeech.TextToSpeechClient()

    synthesis_input = texttospeech.SynthesisInput(text=text)

    voice = texttospeech.VoiceSelectionParams(
        language_code="ko-KR",
        name=voice_name  # ko-KR-Neural2-A (ì—¬ì„±), ko-KR-Neural2-C (ë‚¨ì„±)
    )

    audio_config = texttospeech.AudioConfig(
        audio_encoding=texttospeech.AudioEncoding.MP3,
        speaking_rate=1.0,  # 0.25 ~ 4.0
        pitch=0.0           # -20.0 ~ 20.0
    )

    response = client.synthesize_speech(
        input=synthesis_input,
        voice=voice,
        audio_config=audio_config
    )

    with open(output_path, "wb") as f:
        f.write(response.audio_content)

    print(f"Audio saved to {output_path}")

# ì‚¬ìš©
generate_tts("ì•ˆë…•í•˜ì„¸ìš”, ì˜¤ëŠ˜ì€ ë©‹ì§„ í•˜ë£¨ì…ë‹ˆë‹¤.", "output.mp3")
```

**SSML í™œìš©** (ê³ ê¸‰):
```python
ssml_text = """
<speak>
  ì•ˆë…•í•˜ì„¸ìš”.
  <break time="500ms"/>
  ì˜¤ëŠ˜ì€ <emphasis level="strong">ì •ë§ ë©‹ì§„</emphasis> í•˜ë£¨ì…ë‹ˆë‹¤.
  <prosody rate="slow" pitch="+2st">ì²œì²œíˆ ë†’ì€ ëª©ì†Œë¦¬ë¡œ</prosody>
</speak>
"""

synthesis_input = texttospeech.SynthesisInput(ssml=ssml_text)
```

---

### YouTube Data API v3

**ìš©ë„**: ì˜ìƒ ì—…ë¡œë“œ ìë™í™”

**ê°€ê²©**: ë¬´ë£Œ (ì¼ì¼ ì¿¼í„°: 10,000 units, ì—…ë¡œë“œ 1íšŒ = 1600 units)

**ë¬¸ì„œ**: https://developers.google.com/youtube/v3

**OAuth ì„¤ì •**:
```bash
# 1. GCP Consoleì—ì„œ OAuth 2.0 í´ë¼ì´ì–¸íŠ¸ ID ìƒì„±
# 2. credentials.json ë‹¤ìš´ë¡œë“œ
# 3. ì²« ì‹¤í–‰ ì‹œ ë¸Œë¼ìš°ì €ì—ì„œ ì¸ì¦

pip install google-auth google-auth-oauthlib google-auth-httplib2 google-api-python-client
```

**ì‚¬ìš© ì˜ˆì‹œ**:
```python
import os
from google.oauth2.credentials import Credentials
from google_auth_oauthlib.flow import InstalledAppFlow
from googleapiclient.discovery import build
from googleapiclient.http import MediaFileUpload

SCOPES = ['https://www.googleapis.com/auth/youtube.upload']

def authenticate():
    creds = None
    if os.path.exists('token.json'):
        creds = Credentials.from_authorized_user_file('token.json', SCOPES)

    if not creds or not creds.valid:
        flow = InstalledAppFlow.from_client_secrets_file('credentials.json', SCOPES)
        creds = flow.run_local_server(port=0)
        with open('token.json', 'w') as token:
            token.write(creds.to_json())

    return build('youtube', 'v3', credentials=creds)

def upload_video(youtube, file_path: str, title: str, description: str, tags: list, privacy: str = "private"):
    body = {
        'snippet': {
            'title': title,
            'description': description,
            'tags': tags,
            'categoryId': '22'  # People & Blogs
        },
        'status': {
            'privacyStatus': privacy,  # public, unlisted, private
            'selfDeclaredMadeForKids': False
        }
    }

    media = MediaFileUpload(file_path, chunksize=-1, resumable=True)

    request = youtube.videos().insert(
        part='snippet,status',
        body=body,
        media_body=media
    )

    response = None
    while response is None:
        status, response = request.next_chunk()
        if status:
            print(f"Uploaded {int(status.progress() * 100)}%")

    print(f"Upload complete! Video ID: {response['id']}")
    return f"https://www.youtube.com/watch?v={response['id']}"

# ì‚¬ìš©
youtube = authenticate()
url = upload_video(
    youtube,
    "output.mp4",
    "ğŸ”¥ TOP 10 ê³ ì–‘ì´ ìˆœê°„ë“¤",
    "2024ë…„ ìµœê³ ì˜ ê³ ì–‘ì´ ì˜ìƒ ëª¨ìŒ\n\nì¶œì²˜: Pexels (CC0)",
    ["ê³ ì–‘ì´", "TOP10", "ì‡¼ì¸ "],
    privacy="public"
)
print(url)
```

---

## ì›¹ ìŠ¤íƒ (Phase 4)

### FastAPI

**ìš©ë„**: REST API ì„œë²„

**ì¥ì **:
- ë¹ ë¦„ (Starlette ê¸°ë°˜)
- ìë™ ë¬¸ì„œí™” (OpenAPI/Swagger)
- íƒ€ì… íŒíŒ… & ê²€ì¦ (Pydantic)
- WebSocket ì§€ì›

**ì˜ˆì‹œ**:
```python
from fastapi import FastAPI, BackgroundTasks, UploadFile, File
from pydantic import BaseModel
from typing import List

app = FastAPI()

class RenderRequest(BaseModel):
    items: List[dict]
    style: str = "modern"
    aspect_ratio: str = "9:16"

@app.post("/api/shorts/render")
async def render_shorts(request: RenderRequest, background_tasks: BackgroundTasks):
    task_id = generate_task_id()

    background_tasks.add_task(
        render_task,
        task_id=task_id,
        data=request.dict()
    )

    return {"task_id": task_id, "status": "processing"}

@app.get("/api/tasks/{task_id}")
async def get_task(task_id: str):
    # Redisì—ì„œ ìƒíƒœ ì¡°íšŒ
    status = redis_client.get(f"task:{task_id}")
    return {"task_id": task_id, "status": status}

@app.post("/api/upload/csv")
async def upload_csv(file: UploadFile = File(...)):
    contents = await file.read()
    # CSV íŒŒì‹±
    return {"filename": file.filename, "rows": 10}

# ì‹¤í–‰
# uvicorn src.api.main:app --reload --host 0.0.0.0 --port 8000
```

---

### Celery + Redis

**ìš©ë„**: ë¹„ë™ê¸° ë°±ê·¸ë¼ìš´ë“œ ì‘ì—… (ë Œë”ë§)

**ì„¤ì •**:
```python
# src/api/celery_app.py
from celery import Celery

celery_app = Celery(
    'tasks',
    broker='redis://localhost:6379/0',
    backend='redis://localhost:6379/0'
)

celery_app.conf.update(
    task_serializer='json',
    accept_content=['json'],
    result_serializer='json',
    timezone='Asia/Seoul',
    enable_utc=True,
)
```

**Task ì •ì˜**:
```python
# src/api/tasks.py
from src.api.celery_app import celery_app
from src.shorts.batch_renderer import BatchRenderer

@celery_app.task(bind=True)
def render_task(self, task_id: str, data: dict):
    try:
        # ì§„í–‰ë¥  ì—…ë°ì´íŠ¸
        self.update_state(state='PROGRESS', meta={'progress': 10})

        renderer = BatchRenderer(style=data['style'])

        # ë Œë”ë§ (ì§„í–‰ë¥  ì½œë°±)
        video_path = renderer.render(data['items'], output_dir=f"output/{task_id}")

        self.update_state(state='PROGRESS', meta={'progress': 90})

        # S3 ì—…ë¡œë“œ (optional)
        # s3_url = upload_to_s3(video_path)

        return {'status': 'completed', 'video_url': video_path}

    except Exception as e:
        self.update_state(state='FAILURE', meta={'error': str(e)})
        raise
```

**Worker ì‹¤í–‰**:
```bash
celery -A src.api.celery_app worker --loglevel=info
```

---

### Next.js (í”„ë¡ íŠ¸ì—”ë“œ)

**ìš©ë„**: ì›¹ UI

**ì£¼ìš” í˜ì´ì§€**:
```
pages/
â”œâ”€â”€ index.tsx           # í™ˆ (í”„ë¡œì íŠ¸ ì„ íƒ)
â”œâ”€â”€ shorts/
â”‚   â”œâ”€â”€ upload.tsx      # CSV ì—…ë¡œë“œ
â”‚   â”œâ”€â”€ preview.tsx     # ìŠ¤íƒ€ì¼ ì„ íƒ & ë¯¸ë¦¬ë³´ê¸°
â”‚   â””â”€â”€ result.tsx      # ê²°ê³¼ ë‹¤ìš´ë¡œë“œ
â””â”€â”€ api/
    â””â”€â”€ render.ts       # Proxy to FastAPI
```

**ì˜ˆì‹œ (ì—…ë¡œë“œ í˜ì´ì§€)**:
```tsx
// pages/shorts/upload.tsx
import { useState } from 'react'
import { useRouter } from 'next/router'

export default function ShortsUpload() {
  const [file, setFile] = useState(null)
  const router = useRouter()

  const handleSubmit = async () => {
    const formData = new FormData()
    formData.append('file', file)

    const response = await fetch('/api/render', {
      method: 'POST',
      body: formData
    })

    const { task_id } = await response.json()
    router.push(`/shorts/result?task_id=${task_id}`)
  }

  return (
    <div className="container">
      <h1>ì‡¼ì¸  ë­í‚¹ ì˜ìƒ ìƒì„±</h1>
      <input type="file" accept=".csv" onChange={(e) => setFile(e.target.files[0])} />
      <button onClick={handleSubmit}>ìƒì„± ì‹œì‘</button>
    </div>
  )
}
```

---

## ë°°í¬

### Docker

**Dockerfile**:
```dockerfile
FROM python:3.10-slim

# FFmpeg ì„¤ì¹˜
RUN apt-get update && apt-get install -y ffmpeg && rm -rf /var/lib/apt/lists/*

WORKDIR /app

COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

COPY . .

CMD ["uvicorn", "src.api.main:app", "--host", "0.0.0.0", "--port", "8000"]
```

**docker-compose.yml**:
```yaml
version: '3.8'

services:
  api:
    build: .
    ports:
      - "8000:8000"
    environment:
      - REDIS_URL=redis://redis:6379
    volumes:
      - ./output:/app/output
    depends_on:
      - redis

  worker:
    build: .
    command: celery -A src.api.celery_app worker --loglevel=info
    environment:
      - REDIS_URL=redis://redis:6379
    volumes:
      - ./output:/app/output
    depends_on:
      - redis

  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"

  frontend:
    build: ./frontend
    ports:
      - "3000:3000"
    environment:
      - NEXT_PUBLIC_API_URL=http://localhost:8000
```

---

## ì„±ëŠ¥ ìµœì í™”

### FFmpeg í•˜ë“œì›¨ì–´ ê°€ì†

**NVIDIA GPU (NVENC)**:
```bash
# ì¸ì½”ë”© 2~5ë°° ë¹ ë¦„
ffmpeg -hwaccel cuda -i input.mp4 -c:v h264_nvenc -preset fast output.mp4
```

**Intel QSV**:
```bash
ffmpeg -hwaccel qsv -c:v h264_qsv -i input.mp4 -c:v h264_qsv output.mp4
```

**Apple Silicon (VideoToolbox)**:
```bash
ffmpeg -hwaccel videotoolbox -i input.mp4 -c:v h264_videotoolbox output.mp4
```

---

### Celery ë¶„ì‚° ì²˜ë¦¬

```yaml
# docker-composeì—ì„œ worker ìŠ¤ì¼€ì¼ ì•„ì›ƒ
docker-compose up --scale worker=4
```

---

### Redis ìºì‹±

```python
import redis
import json

redis_client = redis.Redis(host='localhost', port=6379, decode_responses=True)

# Asset ê²€ìƒ‰ ê²°ê³¼ ìºì‹± (24ì‹œê°„)
def search_with_cache(keyword: str):
    cache_key = f"asset:{keyword}"
    cached = redis_client.get(cache_key)

    if cached:
        return json.loads(cached)

    # API í˜¸ì¶œ
    results = fetch_from_pexels(keyword)

    redis_client.setex(cache_key, 86400, json.dumps(results))
    return results
```

---

## ëª¨ë‹ˆí„°ë§

### Sentry (ì—ëŸ¬ ì¶”ì )

```python
import sentry_sdk

sentry_sdk.init(
    dsn="YOUR_SENTRY_DSN",
    traces_sample_rate=1.0
)

# ìë™ ì—ëŸ¬ ìº¡ì²˜
```

---

### Prometheus (ë©”íŠ¸ë¦­)

```python
from prometheus_client import Counter, Histogram, start_http_server

render_count = Counter('video_renders_total', 'Total renders')
render_duration = Histogram('video_render_duration_seconds', 'Render duration')

@render_duration.time()
def render_video():
    # ë Œë”ë§ ë¡œì§
    render_count.inc()

# ë©”íŠ¸ë¦­ ì„œë²„
start_http_server(8001)
```

---

## ê°œë°œ ë„êµ¬

### ì½”ë“œ í’ˆì§ˆ

```bash
# Linting
pip install ruff
ruff check src/

# Formatting
pip install black
black src/

# Type checking
pip install mypy
mypy src/
```

### í…ŒìŠ¤íŠ¸

```bash
pip install pytest pytest-asyncio

# ì‹¤í–‰
pytest tests/ -v
```

---

## ì´ ë¹„ìš© (ì›”ê°„ ì˜ˆìƒ)

| í•­ëª© | ë¹„ìš© |
|------|------|
| Vrew Pro | â‚©10,000 (~$8) |
| Canva Pro (ì„ íƒ) | $13 |
| Google Cloud TTS (ì„ íƒ) | $0-16 |
| AWS EC2 t3.medium (ì„ íƒ) | $30 |
| S3 ìŠ¤í† ë¦¬ì§€ 100GB (ì„ íƒ) | $2 |
| **ë¡œì»¬ ê°œë°œ** | **$0-10** |
| **í´ë¼ìš°ë“œ ë°°í¬** | **$30-60** |

---

## ë‹¤ìŒ ë‹¨ê³„

1. ê°œë°œ í™˜ê²½ ì„¸íŒ… (Python, FFmpeg)
2. requirements.txt ì‘ì„± & íŒ¨í‚¤ì§€ ì„¤ì¹˜
3. Pexels API í‚¤ ë°œê¸‰
4. ìƒ˜í”Œ í´ë¦½ ì¤€ë¹„
5. ì²« í…ŒìŠ¤íŠ¸ ë Œë”ë§
