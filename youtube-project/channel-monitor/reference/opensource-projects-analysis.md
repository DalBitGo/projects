# 오픈소스 YouTube 채널 모니터링 프로젝트 분석

## 목차
1. [프로젝트 1: youtube-channel-analytics (JensBender)](#프로젝트-1-youtube-channel-analytics)
2. [프로젝트 2: youtube-data-analytics-tools (DannyIbo)](#프로젝트-2-youtube-data-analytics-tools)
3. [두 프로젝트 비교 분석](#두-프로젝트-비교-분석)
4. [우리 프로젝트에 적용할 교훈](#우리-프로젝트에-적용할-교훈)

---

## 프로젝트 1: youtube-channel-analytics

**GitHub**: https://github.com/JensBender/youtube-channel-analytics

### 프로젝트 개요
엔터프라이즈급 ETL 파이프라인과 Power BI 대시보드를 결합한 YouTube 채널 분석 시스템. 3개 채널을 비교 분석하며, 감정 분석 기능까지 포함한 종합적인 솔루션.

### 개발자가 발견한 문제점
1. **단일 채널 분석의 한계**
   - 기존 도구들은 대부분 단일 채널 분석에만 집중
   - 여러 채널을 비교하기 어려움
   - 경쟁 채널이나 유사 채널과의 성과 비교 불가

2. **감정 분석의 부재**
   - 시청자 감정(sentiment)이 채널 성장에 중요한 영향
   - 대부분의 도구가 정량적 지표(조회수, 좋아요)만 제공
   - 댓글의 감정적 반응을 분석하는 기능 부족

### 해결 방법

#### 1. 기술 스택 선택과 이유

**Apache Airflow + Docker**
- **고민**: ETL 작업을 어떻게 자동화하고 스케줄링할 것인가?
- **선택 이유**:
  - Airflow는 복잡한 데이터 파이프라인을 DAG(Directed Acyclic Graph)로 관리
  - 각 작업의 의존성 관리와 재시도 로직 자동화
  - Docker로 환경 일관성 보장
- **트레이드오프**:
  - 설정 복잡도 높음 (초보자에게는 진입 장벽)
  - 하지만 확장성과 유지보수성 확보

**AWS (EC2 + RDS)**
- **고민**: 데이터를 어디에 저장하고 어떻게 접근할 것인가?
- **선택**:
  - EC2 t2.micro (무료 티어)에서 Airflow 실행
  - RDS MySQL에 데이터 저장
  - 보안을 위해 RDS는 Public Accessibility를 No로 설정
- **해결한 문제**: SSH 터널을 통해 로컬 Power BI에서 RDS 접근
  - 포트 포워딩: 로컬 3308 → RDS 3306
  - 보안성과 접근성 모두 확보

**Hugging Face + Gradio**
- **고민**: 감정 분석 모델을 어떻게 배포하고 호출할 것인가?
- **선택**:
  - RoBERTa 모델 (125M 파라미터, 124M 트윗으로 학습)
  - Hugging Face Space에 Gradio로 API 배포
  - Private Space로 보안 유지
- **이유**:
  - ETL 파이프라인과 모델 추론을 분리 (관심사의 분리)
  - 무료 GPU/CPU 리소스 활용
  - API 엔드포인트로 간편하게 호출 가능

**Power BI**
- **고민**: 데이터를 어떻게 시각화할 것인가?
- **선택 이유**:
  - 인터랙티브한 대시보드 생성 가능
  - MySQL 직접 연결로 실시간 데이터 반영
  - 필터링, 드릴다운 등 강력한 분석 기능
- **한계**: Windows 전용 (macOS/Linux 사용자는 대안 필요)

#### 2. ETL 파이프라인 설계

**Extract (추출)**
- YouTube Data API v3 사용
- 3개 채널의 데이터 수집:
  - 영상 메타데이터 (제목, 설명, 태그)
  - 조회수, 좋아요, 댓글 수
  - 댓글 텍스트

**Transform (변환)**
- 댓글에 대한 감정 분석
  - Positive, Neutral, Negative로 분류
  - Hugging Face API 호출을 통한 추론
- 데이터 정규화 및 클린징

**Load (적재)**
- MySQL 데이터베이스에 저장
- 정규화된 테이블 구조 (추정):
  - channels, videos, comments, sentiments

#### 3. 폴더 구조와 의미

```
youtube-channel-analytics/
├── dags/                    # Airflow DAG 정의 파일들
├── huggingface_space/       # 감정 분석 모델 배포용
│   ├── app_roberta.py       # Gradio 웹 앱
│   └── requirements.txt     # 모델 의존성
├── images/                  # 문서용 이미지
├── exploration.ipynb        # 탐색적 데이터 분석 (EDA)
├── dashboard.pbix           # Power BI 대시보드 파일
├── docker-compose.yaml      # Airflow 컨테이너 오케스트레이션
├── Dockerfile               # 커스텀 이미지 정의
├── airflow_start_ec2.sh     # EC2 시작 스크립트
├── airflow_start_local.sh   # 로컬 개발용 스크립트
└── create_mysql_database.sql # 데이터베이스 스키마
```

**폴더 구조의 의도**:
- **dags**: Airflow의 핵심, 워크플로우 로직 모음
- **huggingface_space**: 감정 분석 독립 배포 (마이크로서비스 패턴)
- **exploration.ipynb**: 초기 분석과 프로토타이핑용
- **스크립트 분리**: EC2용/로컬용 구분으로 다양한 환경 지원

### 주요 기능

#### Power BI 대시보드 구성
1. **Home Page**: 채널 간 비교 (구독자, 조회수, 좋아요, 평균값)
2. **Comments Page**: 댓글 분석 및 감정 추이
3. **Videos Page**: 영상 업로드 패턴 분석
4. **Top 5 Videos Page**: 조회수/좋아요/댓글 기준 상위 영상

### 배운 점과 한계

**강점**:
- 프로덕션 레벨의 아키텍처 (확장 가능, 자동화)
- 감정 분석으로 정성적 인사이트 추가
- 인프라 자동화 (IaC 접근)

**한계**:
- 3개 채널 제한 (하드코딩된 것으로 추정)
- 설정 복잡도 높음 (초보자에게 진입 장벽)
- 비용 발생 가능성 (AWS 무료 티어 이후)

---

## 프로젝트 2: youtube-data-analytics-tools

**GitHub**: https://github.com/DannyIbo/youtube-data-analytics-tools

### 프로젝트 개요
Flask 기반의 간단한 브라우저 인터페이스 도구. 최대 3개 채널 비교 및 댓글 분석 기능 제공. 실무에서 반복되는 작업을 자동화하기 위해 개발됨.

### 개발 동기
**개발자의 배경**:
- 분석가/컨설턴트로 일하면서 반복 작업에 많은 시간 소비
- 특히 비디오 프로덕션 회사에서 콘텐츠 인텔리전스 업무
- **목표**: 자주 필요한 작업을 자동화

### 기술 스택 선택

**Flask**
- **이유**:
  - Python 웹 프레임워크 중 가장 가볍고 간단
  - 빠른 프로토타이핑 가능
  - 학습 곡선이 낮음
- **트레이드오프**:
  - 복잡한 기능 추가 시 구조화 어려움
  - 프로덕션 배포 시 추가 설정 필요

**Pandas**
- **이유**:
  - YouTube API 응답을 DataFrame으로 변환하여 쉽게 분석
  - 데이터 조작과 집계 간편
  - Matplotlib/Seaborn과 자연스럽게 연동

**Matplotlib + Seaborn + WordCloud**
- **이유**:
  - Python 시각화 표준 라이브러리
  - 이미지 파일로 저장 후 웹에 표시 (간단한 아키텍처)
  - WordCloud로 텍스트 데이터 직관적 시각화

### 주요 기능

#### 1. 채널 비교 기능
- **비디오 개수 비교** (막대 그래프)
- **링크 분석**: 설명란의 클릭 가능/불가능 링크 개수
  - 고민: 왜 이 기능이 필요했을까?
  - 추측: SEO나 마케팅 전략 분석용
  - `https://`로 시작하는지 체크
- **비디오 태그 워드 클라우드**: 어떤 키워드를 많이 사용하는지
- **영상 길이 히스토그램**: 채널별 영상 길이 분포
- **Top 5 조회수 영상 테이블**

#### 2. 댓글 분석 기능
- **시계열 라인 플롯**: 댓글 수의 누적 합 및 감정별 추이
- **감정-좋아요 산점도**: 댓글 감정과 좋아요 수 관계 (로그 스케일)
- **댓글 워드 클라우드**: 가장 많이 사용된 단어 (영어 불용어 제거)

### 폴더 구조

```
youtube-data-analytics-tools/
├── app.py               # Flask 메인 애플리케이션
├── src/                 # 핵심 로직 (API 호출, 데이터 처리)
├── templates/           # HTML 템플릿 (Jinja2)
├── static/              # CSS, JS, 생성된 플롯 이미지
├── example_plots/       # 데모/문서용 예시 이미지
└── requirements.txt     # Python 의존성
```

**구조의 의도**:
- **MVC 패턴 준수**: app.py (Controller), templates (View), src (Model)
- **static 폴더**: 생성된 플롯을 임시 저장하여 웹에 표시
- **간결함 우선**: 복잡한 폴더 계층 없이 평평한 구조

### 개발자가 마주한 문제들

#### 1. API 할당량 제한
**문제**:
- YouTube Data API v3 무료 할당량: 하루 10,000 쿼리
- 채널에 영상이 많거나 댓글이 많으면 쉽게 초과
- 테스트 결과: 4,000개 영상 채널, 1,000개 댓글 영상까지는 작동

**미해결**:
- 유료 API로 업그레이드하거나
- 쿼리 비용 사전 예측 기능 필요
- 현재는 사용자가 알아서 조절해야 함

#### 2. 파일 관리 문제
**문제**:
- 플롯 이미지를 생성하지만 삭제하지 않음
- 시간이 지나면 디스크 공간 부족 가능성

**해결 방안 (미구현)**:
- 스케줄러로 정기적 삭제
- 임시 파일 시스템 사용
- 메모리에서 직접 스트리밍 (Base64 인코딩)

#### 3. 파일명 길이 문제
**문제**:
- 채널 ID를 조합하여 파일명 생성
- 3개 채널은 괜찮지만, 더 많아지면 파일명이 너무 길어짐
- 운영체제의 파일명 길이 제한 (예: 255자)

**현재 해결책**:
- URL로 채널 개수 늘리는 것은 가능하지만 권장하지 않음
- 3개 제한이 실질적 권장사항

#### 4. 다국어 지원 부족
**문제**:
- 워드 클라우드가 영어 불용어만 제거
- 한국어, 일본어 등 다른 언어 댓글 분석 시 의미 없는 결과

**해결 방안 (미구현)**:
- 언어 선택 옵션 추가
- 다국어 불용어 라이브러리 통합

#### 5. 시각화 표현 문제
**문제**:
- 일부 그래프에서 정수여야 할 값이 소수점으로 표시
- 예: "2.5개 영상" (의미 없음)

**원인 추측**:
- Matplotlib 자동 축 레이블링
- Pandas 집계 시 float 타입 반환

### 배운 점과 한계

**강점**:
- 간단하고 빠른 프로토타이핑
- 브라우저 UI로 비개발자도 사용 가능
- 실무 문제 해결에 집중 (실용성)

**한계**:
- 3개 채널 제한 (파일명 문제로 더 늘리기 어려움)
- API 할당량 관리 부재
- 파일 정리 자동화 없음
- 프로덕션 레벨 아님 (개인 도구 수준)

**개발 철학**:
- "작동하는 것부터 빠르게 만들고, 나중에 개선"
- To Do 리스트가 명확히 남아있음 (투명한 개발)

---

## 두 프로젝트 비교 분석

| 항목 | youtube-channel-analytics | youtube-data-analytics-tools |
|------|---------------------------|------------------------------|
| **복잡도** | 높음 (엔터프라이즈급) | 낮음 (프로토타입 수준) |
| **채널 수** | 3개 (확장 가능성 높음) | 3개 (URL로 더 가능하지만 비권장) |
| **인프라** | AWS (EC2 + RDS) | 로컬 실행 |
| **자동화** | Apache Airflow (스케줄링) | 수동 실행 (Flask) |
| **데이터 저장** | MySQL (영구 저장) | 메모리 (세션 단위) |
| **시각화** | Power BI (인터랙티브) | 정적 이미지 (Matplotlib) |
| **감정 분석** | RoBERTa (125M 파라미터) | 있음 (구체적 모델 불명) |
| **배포** | Docker + 클라우드 | 로컬 Flask 서버 |
| **진입 장벽** | 높음 | 낮음 |
| **유지보수** | 구조화됨 | 개선 필요 사항 많음 |
| **비용** | AWS 비용 발생 가능 | 무료 (API 한도 내) |

### 설계 철학 차이

**youtube-channel-analytics**:
- "확장 가능하고 유지보수 가능한 시스템"
- ETL 파이프라인 패턴
- 마이크로서비스 지향 (감정 분석 분리)
- 데이터 영속성 중시

**youtube-data-analytics-tools**:
- "빠르게 만들어서 실무에 바로 사용"
- 모놀리식 Flask 앱
- 간단한 아키텍처
- 일회성 분석 중심

---

## 우리 프로젝트에 적용할 교훈

### 1. 기술 스택 선택 기준

**고려 사항**:
- **채널 수**: 10개 이상 → 확장성 중요
- **자동화 필요성**: 정기적 모니터링 → Airflow 같은 스케줄러 고려
- **학습 목표**: Python 깊이 파기 → 복잡도는 점진적으로

**추천 접근**:
1. **Phase 1**: DannyIbo처럼 간단하게 시작 (Flask + Pandas)
2. **Phase 2**: 데이터 영속성 추가 (SQLite → MySQL)
3. **Phase 3**: 자동화 추가 (간단한 cron → Airflow)

### 2. 해결해야 할 핵심 문제

#### 채널 수 제한 극복
**두 프로젝트 모두 3개 제한**:
- DannyIbo: 파일명 길이 문제
- JensBender: 명시적 제한 없지만 3개만 다룸

**우리의 해결책**:
- 파일명에 채널 ID 직접 사용 대신 해시 또는 순차 번호 사용
- 데이터베이스에 채널 정보 저장 (파일명 문제 회피)
- 동적 UI (채널 추가/제거 가능)

#### API 할당량 관리
**DannyIbo가 지적한 문제**:
- 하루 10,000 쿼리 제한
- 대형 채널은 쿼리 비용 높음

**우리의 해결책**:
- 쿼리 비용 사전 계산 로직
- 증분 업데이트 (전체가 아닌 변경분만)
- 캐싱 전략 (자주 변하지 않는 데이터)
- 할당량 모니터링 대시보드

#### 데이터 저장 vs 일회성 분석
**트레이드오프**:
- 저장: 추세 분석 가능, 디스크/DB 필요
- 일회성: 간단, 과거 데이터 없음

**우리의 선택**:
- 시계열 분석 필요 → 반드시 저장
- 초기: SQLite (설정 간단)
- 나중: MySQL/PostgreSQL (확장성)

### 3. 피해야 할 함정

1. **과도한 엔지니어링**: 처음부터 JensBender처럼 AWS + Airflow는 부담
2. **파일 정리 간과**: DannyIbo의 실수 반복하지 말기
3. **하드코딩된 제한**: 채널 수를 코드에 고정하지 말 것
4. **다국어 고려 부족**: 한국어 댓글 분석 시 불용어 처리 필수

### 4. UI/UX 인사이트

**JensBender의 Power BI 구조 참고**:
```
채널 목록 (필터 가능)
  ├─ 전체 비교 대시보드
  │   ├─ 구독자/조회수/좋아요 비교
  │   ├─ 시간대별 필터링
  │   └─ 평균값 계산 (영상당, 1000 조회당)
  │
  ├─ 댓글 분석 페이지
  │   ├─ 총 댓글 수
  │   ├─ 월별 추세
  │   └─ 감정 분석 결과
  │
  ├─ 영상 분석 페이지
  │   ├─ 업로드 패턴
  │   └─ 영상 길이 통계
  │
  └─ 개별 영상 상세
      ├─ Top 5 랭킹
      └─ 클릭 가능한 영상 링크
```

**DannyIbo의 인터랙션 참고**:
- 브라우저에서 채널 ID 입력 → 즉시 분석
- 결과를 이미지로 표시 (간단하지만 효과적)

### 5. 개발 로드맵 제안

#### MVP (Minimum Viable Product)
1. Flask 웹 앱
2. 10개 채널 ID 입력 받기
3. YouTube API로 기본 지표 수집 (구독자, 조회수)
4. 테이블로 비교 표시
5. SQLite에 저장

#### Version 2
1. 영상별 상세 페이지
2. 시계열 그래프 (Matplotlib)
3. API 할당량 모니터링

#### Version 3
1. 자동화 (APScheduler → Airflow)
2. 감정 분석 추가
3. 대시보드 UI 개선 (React?)

### 6. 라이브러리 선택 가이드

**두 프로젝트 공통 사용**:
- `google-api-python-client`: YouTube API 공식 클라이언트
- `pandas`: 데이터 처리
- `matplotlib/seaborn`: 시각화

**우리가 추가로 고려할 것**:
- `python-dotenv`: 환경 변수 관리
- `SQLAlchemy`: ORM (데이터베이스 추상화)
- `APScheduler`: 간단한 스케줄링 (Airflow 전 단계)
- `pytest`: 테스트 자동화

### 7. 문서화 중요성

**두 프로젝트 모두 README 잘 작성됨**:
- JensBender: 상세한 설치 가이드 (AWS, API 키 등)
- DannyIbo: To Do 리스트로 한계 명시

**우리의 문서화 전략**:
- 개발 과정 기록 (이 문서처럼)
- 설치/실행 가이드
- API 사용법
- 알려진 이슈와 해결 방법

---

## 다음 단계: 코드 분석

이제 README를 통해 전체적인 맥락을 파악했으니, 다음은:
1. `app.py` (DannyIbo) - Flask 앱 구조 이해
2. `dags/` (JensBender) - Airflow DAG 로직 분석
3. YouTube API 호출 코드 - 어떤 엔드포인트를 어떻게 사용하는지
4. 데이터 스키마 - MySQL 테이블 구조

이를 통해 실제 구현 방법을 배울 수 있습니다.
